{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "Fill in image of hand-written notes which are easy to read, or latex equations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "Fill in image of hand-written notes which are easy to read, or latex equations here\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "## task 1d)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "## task 1e)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "## task 1f)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "## task 1g)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2a)\n",
    "![](plots/task2_plot.png)\n",
    "\n",
    "### Task 2b)\n",
    "Our final test accuracies were the following:\n",
    "- Training set accuracy: 87,9%\n",
    "- Validation set accuracy: 73,5%\n",
    "- Testing set accuracy: 73,4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "#### Model 1\n",
    "During the tuning process we tried tweaking the parameters mentioned below, as well as the activation function. Model 1 represents the parameter tuning that gave the best performance increase considering each parameter separately.\n",
    "\n",
    "This model is altered from the original task 2 model in the following:\n",
    "* Data augmentation where 50% of the dataset is randomly mirrored and 10% has introduced contrast and saturation jitter.\n",
    "* Filter size is reduced to 3x3.\n",
    "* Batch normalization is introduced after every convolutional and fully connected layer.\n",
    "* As is shown in the table below, the number of filters is increased and the network achitecture is deeper.\n",
    "* Training details are unaltered and default, including optimizer, regularization, learning rate and batch size \n",
    "\n",
    "| Layer |  Layer Type  | Hidden units/filters | Activation f. |\n",
    "|:-----:|:------------:|:--------------------:|:-------------:|\n",
    "|   1   |    Conv2D    |          64          |      ReLU     |\n",
    "|   1   |    Conv2D    |          64          |      ReLU     |\n",
    "|   1   |   MaxPool2D  |          -           |       -       |\n",
    "|   2   |    Conv2D    |         128          |      ReLU     |\n",
    "|   2   |    Conv2D    |         128          |      ReLU     |\n",
    "|   2   |   MaxPool2D  |          -           |       -       |\n",
    "|   3   |    Conv2D    |         256          |      ReLU     |\n",
    "|   3   |    Conv2D    |         256          |      ReLU     |\n",
    "|   3   |   MaxPool2D  |          -           |       -       |\n",
    "|-------|--------------|----------------------|---------------|\n",
    "|       |    Flatten   |          -           |      ReLU     |\n",
    "|   4   |     FCNN     |          64          |      ReLU     |\n",
    "|   5   |     FCNN     |          10          |       -       |\n",
    "\n",
    "#### Model 2\n",
    "Model 2 represents the parameter tuning that gave the best performance increase considering all methods in conjunction.\n",
    "\n",
    "This model is altered from the original task 2 model in the following:\n",
    "* Data augmentation where 50% of the dataset is randomly mirrored and **20%** has introduced contrast and saturation jitter.\n",
    "* Filter size is reduced to 3x3.\n",
    "* Batch normalization is introduced after every convolutional and fully connected layer.\n",
    "* As is shown in the table below, the number of filters is increased and the network achitecture is deeper.\n",
    "* Training details are unaltered and default, including optimizer, regularization, learning rate and batch size \n",
    "\n",
    "| Layer |  Layer Type  | Hidden units/filters | Activation f. |\n",
    "|:-----:|:------------:|:--------------------:|:-------------:|\n",
    "|   1   |    Conv2D    |          64          |      ReLU     |\n",
    "|   1   |    Conv2D    |          64          |      ReLU     |\n",
    "|   1   |   MaxPool2D  |          -           |       -       |\n",
    "|   2   |    Conv2D    |         128          |      ReLU     |\n",
    "|   2   |    Conv2D    |         128          |      ReLU     |\n",
    "|   2   |   MaxPool2D  |          -           |       -       |\n",
    "|   3   |    Conv2D    |         256          |      ReLU     |\n",
    "|   3   |    Conv2D    |         256          |      ReLU     |\n",
    "|   3   |   MaxPool2D  |          -           |       -       |\n",
    "|-------|--------------|----------------------|---------------|\n",
    "|       |    Flatten   |          -           |      ReLU     |\n",
    "|   4   |     FCNN     |          64          |      ReLU     |\n",
    "|   5   |     FCNN     |          10          |       -       |\n",
    "\n",
    "### Task 3b)\n",
    "|                     | Model 1 | Model 2 |\n",
    "|---------------------|:-------:|:-------:|\n",
    "| Training accuracy   |  83,7%  |  87,2%  |\n",
    "| Validation accuracy |  79,8%  |  83,2%  |\n",
    "| Testing accuracy    |  79,5%  |  82,7%  |\n",
    "\n",
    "#### Model 2 performance\n",
    "![](plots/task3_model2_plot.png)\n",
    "\n",
    "### Task 3c)\n",
    "Of all the methods we decided to implement, we found that adjusting the network architecture and filter number (and filter size to some degree) undoubtedly had the greatest impact on model performance. This is likely because there are so many hyperparameters in a model of this size, and finding the optimal tuning is a very work-intensive process. As such, finding the optimal network architecture first try for instance, is impossible. \n",
    "\n",
    "Data augmentation also had a great effect once the model was made deeper with more layers and filters, but by itself it did not do much. The data augmentation method we implemented in model 1 was what we found to be optimal when only data augmentation was used to improve on the base model from task 2. In fact, model 2 differs from model 1 only in the degree of data augmentation. It turns out that when the model is deeper, more generalized and complex (as is the case for model 2), it responds better to a more diverse dataset. \n",
    "\n",
    "Batch normalization also did not affect model performance, however it did allow for a much faster learning rate, especially in the deeper models. This is likely because of an inate internal covariate shift, which is typical when models grow more complex. Batch normalization was however crucial when adding more layers and growing our model depth. As we promptly realized, adding more layers actually had a negative effect on performance until we also decided to include batch normalization. With this combination, the model excelled!\n",
    "\n",
    "As mentioned above, we also tried swapping the ReLU activation function for others, including LeakyRELU, Hardswish, ELU, PReLU, ReLU6, RReLU, SELU, CELU and GELU. None of these showed any improved performance, however many came very close. With further testing, some activation functions could potentially show promise for more complex models.\n",
    "\n",
    "TODO(?): Try to implement strided convolutions instead of pooling to have something to write about. I intentionally skipped this method because I thought it would have no positive effect on performance.\n",
    "\n",
    "### Task 3d)\n",
    "The plot below shows how the modeled improved by introducing a deeper network architecture and batch normalization\n",
    "![](plots/task3d_plot.png)\n",
    "\n",
    "### Task 3e)\n",
    "We seem to have misunderstood, and implemented a fully optimal model as best we could during task 3a. As such, here is another plot from model 2: :)\n",
    "![](plots/task3_model2_plot.png)\n",
    "\n",
    "### Task 3f)\n",
    "Yes, overfitting is clearly present in our model, as well as in all other models we encountered during tuning. It can be observed by the fact that the training accuracy is always significantly better than both the validation- and testing accuracy. Interestingly, we found that for every act of data augmentation, the training accuracy was reduced while the validation and test accuracy was increased. This is of course desirable behaviour, and is likely because the dataset is generalized in a way. Data augmentation is essentially a way of increasing model performance while reducing overfitting.\n",
    "\n",
    "Overfitting is however not as apparent as was the case in one of our earlier FCNNs. This may be because a 3 channel 32x32 pixel image gives rise to features which are much harder for a model to \"memorize\", compared to much simpler FCNNs. The vastly greater number of model parameters likely also has an effect in this regard. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "![](plots/task4a_plot.png)\n",
    "As can be seen in the above figure, we achieved a training accuracy of 89,9% by utilizing transfer learning with Resnet18."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "![](plots/task4b.png)\n",
    "From the filter activations above, it can be observed how the differing filters affect how horizontal and vertical features are detected to differing degrees. Filter 14, 26 and 49 are better suited to detect sharp vertical (filter 14), horizontal (filter 26) and diagonal (filter 49) edges, which is apparent in the distinct zebra lines for their corresponding activations. Filters 32 and 52 however, detect different color variations than simply greyscale, and are in addition less suited to detect edges because of their \"round\" shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "FILL IN ANSWER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
