{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "![](1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "![](1b_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](task2c_train_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "\n",
    "Our model is comprised of one input layer with 785 nodes (taking bias into account), one hidden layer with 64 nodes, and one output layer with 10 nodes. This gives rise to the following amount of parameters:\n",
    "![equation](http://www.sciweavers.org/tex2img.php?eq=785%2A64%2B64%2A10%3D50880&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](task3a_train_loss.png)\n",
    "In the above figure, the orange graph represent an improved model where the input weights of every node are initialized to a normal distribution with a standard deviation inversely proportional to the number of nodes in the preceding layer. The blue graph represents a model with weights of a uniform distribution. In both models, the weights are initialized to a mean of 0. In the model with improved weights, we get a significant increase in performance, as well as a slight improvement in convergence rate. \n",
    "\n",
    "![](task3b_train_loss.png)\n",
    "This time, we improved our model by implementing a new sigmoid function, as described in _Efficient Backprop, section 4.4_. The improved model is represented by an orange graph in the above figure. It seems clear that the improved model does not present any notable increase in performance. The convergence rate is however drastically improved, by over 250 percent.\n",
    "\n",
    "![](task3c_train_loss.png)\n",
    "By implementing momentum, as described in _Efficient Backprop, section 4.7_, we saw a very slight increase in model performance with slightly less training steps at about the same convergence rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a, 4b)\n",
    "![](task4ab_accuracy.png)\n",
    "As is apparent in the above figure, the number of hidden units affect both model performance and convergance rate. By halving the amount of hidden units from 64 to 32, the validation accuracy is reduced by about 2 percent, while increasing the rate of convergence by about 50 percent. The same tendency can be seen by doubling the amount of hidden units from 64 to 128, where the validation accuracy is increased by about 1 percent. In this case, however, the rate of convergence is reduced to less than half. In conclusion, the amount of hidden units in our model is a trade off between performance and convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "In task 3, the parameter count is equal to that of task 2, which was calculated to be 50880. With two hidden layers of 60 nodes, we end up with the following parameter count:\n",
    "\n",
    "![equation](http://www.sciweavers.org/tex2img.php?eq=785%2A60%2B60%2A60%2B60%2A10&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=0)\n",
    "![](task4d.png)\n",
    "This new model with two hidden layers gives no apparent improvement to the model validation accuracy, even though both models had the same amount of paramenters. The only distiction between the two is is evident in the fluctuation of the validation- and training accuracy during convergence, as well as the rate of convergence. The updated model with two hidden layers converges about 40 percent slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "FILL IN ANSWER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
